# Ditto Scrapper

POC para scrapear contenido de theobjetive.com con interfaz web interactiva

## ğŸŒŸ CaracterÃ­sticas

- âœ… **ExtracciÃ³n completa de artÃ­culos**: tÃ­tulos, autores, fechas, contenido
- âœ… **ValidaciÃ³n de dominio**: solo permite URLs de theobjetive.com
- âœ… **Interfaz web moderna**: aplicaciÃ³n Streamlit responsive y atractiva
- âœ… **MÃºltiples modos**: lÃ­nea de comandos y interfaz grÃ¡fica
- âœ… **EstadÃ­sticas de sesiÃ³n**: seguimiento de extracciones exitosas/fallidas
- âœ… **ExtracciÃ³n inteligente**: detecta automÃ¡ticamente elementos del artÃ­culo

## ğŸ“‹ Requisitos

- Python 3.10+
- Poetry (para gestiÃ³n de dependencias)

## ğŸš€ InstalaciÃ³n RÃ¡pida

```bash
# Clonar el repositorio
git clone <tu-repositorio>
cd ditto-scrapper

# Instalar dependencias
poetry install

# Ejecutar la aplicaciÃ³n web
poetry run streamlit run streamlit_app.py
```

## ğŸ’» Modos de Uso

### 1. ğŸŒ AplicaciÃ³n Web (Streamlit) - **Â¡RECOMENDADO!**

La forma mÃ¡s fÃ¡cil y visual de usar el scraper:

```bash
# OpciÃ³n 1: Usando Poetry
poetry run streamlit run streamlit_app.py

# OpciÃ³n 2: Usando el script helper
poetry run python run_streamlit.py
```

La aplicaciÃ³n se abrirÃ¡ automÃ¡ticamente en `http://localhost:8501`

**CaracterÃ­sticas de la interfaz web:**
- ğŸ“± Interfaz responsive y moderna
- ğŸ¯ URLs de ejemplo pre-configuradas
- ğŸ“Š MÃ©tricas en tiempo real
- ğŸ”§ Modo debug opcional
- ğŸ“„ Vista previa del contenido extraÃ­do

### 2. ğŸ“Ÿ LÃ­nea de Comandos

#### ExtracciÃ³n de artÃ­culo especÃ­fico:
```bash
# Usando el script simple
poetry run python extract_article.py "https://theobjective.com/tu-articulo/"

# Usando el script principal
poetry run python main.py
```

#### Uso programÃ¡tico:
```python
from src.scraper import DittoScraper

scraper = DittoScraper()

# Extraer contenido de un artÃ­culo
article_data = scraper.scrape_article_content("https://theobjective.com/economia/...")

print(f"TÃ­tulo: {article_data['title']}")
print(f"Autor: {article_data['author']}")
print(f"Contenido: {article_data['content']}")
```

## ğŸ—ï¸ Estructura del Proyecto

```
ditto-scrapper/
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ config.toml           # ConfiguraciÃ³n de Streamlit
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ scraper.py           # LÃ³gica principal del scraper
â”œâ”€â”€ streamlit_app.py         # ğŸŒŸ AplicaciÃ³n Streamlit (PRINCIPAL)
â”œâ”€â”€ main.py                  # Ejemplos de uso en terminal
â”œâ”€â”€ extract_article.py       # Script simple de extracciÃ³n
â”œâ”€â”€ run_streamlit.py         # Helper para ejecutar Streamlit
â”œâ”€â”€ requirements.txt         # Dependencias para Streamlit Cloud
â”œâ”€â”€ pyproject.toml          # ConfiguraciÃ³n del proyecto
â”œâ”€â”€ .gitignore              # Archivos a ignorar
â””â”€â”€ README.md               # Este archivo
```

## ğŸŒ Deploy en Streamlit Cloud

### PreparaciÃ³n para Deploy:

1. **Sube tu cÃ³digo a GitHub**
2. **Ve a [share.streamlit.io](https://share.streamlit.io)**
3. **Conecta tu repositorio de GitHub**
4. **Configura el deploy:**
   - **Repository**: `tu-usuario/ditto-scrapper`
   - **Branch**: `main`
   - **Main file path**: `app.py`

### Variables de entorno (opcional):
Si necesitas configuraciones especÃ­ficas, puedes agregar en Streamlit Cloud:
```
STREAMLIT_THEME_PRIMARY_COLOR=#2e86ab
```

## ğŸ› ï¸ Desarrollo

### Agregar nuevas dependencias:
```bash
# Dependencia principal
poetry add nombre-paquete

# Dependencia de desarrollo
poetry add --group dev nombre-paquete
```

### Ejecutar tests (cuando los agregues):
```bash
poetry run pytest
```

### Activar entorno virtual:
```bash
poetry shell
```

## ğŸ“Š API del Scraper

### `DittoScraper.scrape_article_content(url)`

Extrae el contenido completo de un artÃ­culo.

**ParÃ¡metros:**
- `url` (str): URL del artÃ­culo de theobjetive.com

**Retorna:**
```python
{
    'url': 'https://theobjective.com/...',
    'title': 'TÃ­tulo del artÃ­culo',
    'subtitle': 'SubtÃ­tulo si existe',
    'author': 'Nombre del autor',
    'date': 'Fecha de publicaciÃ³n',
    'content': 'Contenido completo del artÃ­culo',
    'tags': ['tag1', 'tag2', ...],
    'category': 'categorÃ­a'
}
```

### ValidaciÃ³n automÃ¡tica:
- âœ… Solo acepta URLs de `theobjective.com`
- âœ… Maneja URLs relativas y absolutas
- âœ… Limpia y normaliza el texto extraÃ­do
- âœ… Filtra contenido irrelevante

## ğŸ¯ URLs de Ejemplo

Para probar la aplicaciÃ³n, puedes usar estas URLs:

1. **ArtÃ­culo de EconomÃ­a**: `https://theobjective.com/economia/energia/2025-07-13/cnmc-directiva-apagon/`
2. **SecciÃ³n EconomÃ­a**: `https://theobjective.com/economia/`
3. **PÃ¡gina Principal**: `https://theobjective.com/`

## âš ï¸ Consideraciones Ã‰ticas

- ğŸ¤ **Respeta el robots.txt** del sitio web
- â±ï¸ **Implementa delays** entre requests para no sobrecargar el servidor
- ğŸ“œ **Respeta los tÃ©rminos de servicio** de theobjetive.com
- ğŸ¯ **Uso responsable**: solo para propÃ³sitos educativos y de investigaciÃ³n

## ğŸ› SoluciÃ³n de Problemas

### Error: "URL no permitida"
- âœ… Verifica que la URL pertenezca a theobjetive.com
- âœ… Incluye `https://` al inicio de la URL

### Error de conexiÃ³n:
- ğŸŒ Verifica tu conexiÃ³n a internet
- ğŸ”„ La pÃ¡gina podrÃ­a estar temporalmente no disponible

### Contenido no extraÃ­do:
- ğŸ” La estructura HTML de la pÃ¡gina podrÃ­a haber cambiado
- ğŸ› ï¸ Activa el modo debug en Streamlit para mÃ¡s informaciÃ³n

## ğŸ”„ Futuras Mejoras

- [ ] Soporte para mÃ¡s sitios web de noticias
- [ ] Exportar datos a CSV/JSON
- [ ] Sistema de cachÃ© para evitar scraping repetido
- [ ] AnÃ¡lisis de sentimientos del contenido
- [ ] API REST para integraciÃ³n con otros sistemas

## ğŸ“ Licencia

MIT

---

<div align="center">

**ğŸš€ Â¡Desarrollado con â¤ï¸ para extraer contenido de forma inteligente!**

</div> 