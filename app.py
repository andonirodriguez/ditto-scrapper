#!/usr/bin/env python3
"""
Aplicaci√≥n Streamlit para el Ditto Scraper
Extrae contenido de art√≠culos de theobjetive.com
"""

import streamlit as st
from src.scraper import DittoScraper
import time
from datetime import datetime

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Ditto Scraper - theobjetive.com",
    page_icon="üì∞",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personalizado para mejorar el dise√±o
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        margin-bottom: 1rem;
        background: linear-gradient(90deg, #1f4e79, #2e86ab);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
    }
    
    .subtitle {
        text-align: center;
        font-size: 1.2rem;
        color: #666;
        margin-bottom: 2rem;
    }
    
    .article-card {
        border: 1px solid #ddd;
        border-radius: 10px;
        padding: 1.5rem;
        margin: 1rem 0;
        background-color: #f8f9fa;
    }
    
    .metric-container {
        display: flex;
        justify-content: space-around;
        margin: 1rem 0;
    }
    
    .success-message {
        padding: 1rem;
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        border-radius: 5px;
        color: #155724;
        margin: 1rem 0;
    }
    
    .error-message {
        padding: 1rem;
        background-color: #f8d7da;
        border: 1px solid #f5c6cb;
        border-radius: 5px;
        color: #721c24;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

def main():
    """Funci√≥n principal de la aplicaci√≥n Streamlit"""
    
    # Header principal
    st.markdown('<h1 class="main-header">üì∞ Ditto Scraper</h1>', unsafe_allow_html=True)
    st.markdown('<p class="subtitle">Extractor de contenido de theobjetive.com</p>', unsafe_allow_html=True)
    
    # Sidebar con informaci√≥n y configuraci√≥n
    with st.sidebar:
        st.header("‚ÑπÔ∏è Informaci√≥n del Proyecto")
        st.markdown("""
        **Ditto Scraper** es una POC para extraer contenido de art√≠culos de theobjetive.com de forma automatizada.
        
        ### Caracter√≠sticas:
        - ‚úÖ Extrae t√≠tulos, autores y fechas
        - ‚úÖ Obtiene el contenido completo del art√≠culo
        - ‚úÖ Identifica categor√≠as y tags
        - ‚úÖ Validaci√≥n de dominio
        - ‚úÖ Interfaz web interactiva
        
        ### Tecnolog√≠as:
        - Python 3.10+
        - BeautifulSoup4
        - Requests
        - Streamlit
        """)
        
        st.divider()
        
        st.header("üîß Configuraci√≥n")
        show_debug = st.checkbox("Mostrar informaci√≥n de debug", value=False)
        
        st.divider()
        
        st.header("üöÄ URLs de Ejemplo")
        example_urls = [
            "https://theobjective.com/economia/energia/2025-07-13/cnmc-directiva-apagon/",
            "https://theobjective.com/economia/",
            "https://theobjective.com/"
        ]
        
        for i, url in enumerate(example_urls, 1):
            if st.button(f"Ejemplo {i}", key=f"example_{i}", use_container_width=True):
                st.session_state.url_input = url
    
    # Contenido principal
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("üîç Extraer Contenido de Art√≠culo")
        
        # Input para la URL
        url_input = st.text_input(
            "Introduce la URL del art√≠culo de theobjetive.com:",
            value=st.session_state.get('url_input', ''),
            placeholder="https://theobjective.com/...",
            help="Pega aqu√≠ la URL completa del art√≠culo que quieres scrapear"
        )
        
        # Botones de acci√≥n
        col_btn1, col_btn2, col_btn3 = st.columns([1, 1, 2])
        
        with col_btn1:
            extract_button = st.button("üöÄ Extraer Contenido", type="primary", use_container_width=True)
        
        with col_btn2:
            clear_button = st.button("üóëÔ∏è Limpiar", use_container_width=True)
        
        if clear_button:
            st.session_state.clear()
            st.rerun()
    
    with col2:
        st.header("üìä Estad√≠sticas de Sesi√≥n")
        
        # Inicializar estad√≠sticas en session_state si no existen
        if 'stats' not in st.session_state:
            st.session_state.stats = {
                'total_extractions': 0,
                'successful_extractions': 0,
                'failed_extractions': 0
            }
        
        stats = st.session_state.stats
        success_rate = (stats['successful_extractions'] / stats['total_extractions'] * 100) if stats['total_extractions'] > 0 else 0
        
        st.metric("Total Extracciones", stats['total_extractions'])
        st.metric("Exitosas", stats['successful_extractions'], 
                 delta=f"{success_rate:.1f}% tasa de √©xito")
        st.metric("Fallidas", stats['failed_extractions'])
    
    # Procesamiento de la extracci√≥n
    if extract_button and url_input.strip():
        
        st.session_state.stats['total_extractions'] += 1
        
        with st.spinner('üîÑ Extrayendo contenido del art√≠culo...'):
            try:
                # Crear instancia del scraper
                scraper = DittoScraper()
                
                # Extraer contenido
                start_time = time.time()
                article_data = scraper.scrape_article_content(url_input.strip())
                end_time = time.time()
                
                # Verificar si se extrajo contenido √∫til
                if article_data['title'] or article_data['content']:
                    st.session_state.stats['successful_extractions'] += 1
                    
                    # Mensaje de √©xito
                    st.markdown(f"""
                    <div class="success-message">
                        ‚úÖ <strong>¬°Contenido extra√≠do exitosamente!</strong><br>
                        Tiempo de procesamiento: {end_time - start_time:.2f} segundos
                    </div>
                    """, unsafe_allow_html=True)
                    
                    # Mostrar informaci√≥n del art√≠culo
                    st.header("üìã Informaci√≥n del Art√≠culo")
                    
                    # M√©tricas principales
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric("üìù Caracteres", len(article_data['content']))
                    
                    with col2:
                        word_count = len(article_data['content'].split()) if article_data['content'] else 0
                        st.metric("üí¨ Palabras", word_count)
                    
                    with col3:
                        st.metric("üè∑Ô∏è Tags", len(article_data['tags']))
                    
                    with col4:
                        reading_time = max(1, word_count // 200)  # ~200 palabras por minuto
                        st.metric("‚è±Ô∏è Lectura", f"{reading_time} min")
                    
                    # Informaci√≥n detallada
                    st.subheader("üìÑ Detalles del Art√≠culo")
                    
                    # Crear dos columnas para la informaci√≥n
                    info_col1, info_col2 = st.columns(2)
                    
                    with info_col1:
                        st.markdown("**üîó URL:**")
                        st.code(article_data['url'])
                        
                        st.markdown("**üì∞ T√≠tulo:**")
                        st.markdown(f"*{article_data['title']}*" if article_data['title'] else "*No encontrado*")
                        
                        st.markdown("**üë§ Autor:**")
                        st.markdown(article_data['author'] if article_data['author'] else "*No encontrado*")
                    
                    with info_col2:
                        st.markdown("**üìÖ Fecha:**")
                        st.markdown(article_data['date'] if article_data['date'] else "*No encontrada*")
                        
                        st.markdown("**üìÇ Categor√≠a:**")
                        st.markdown(article_data['category'] if article_data['category'] else "*No encontrada*")
                        
                        if article_data['tags']:
                            st.markdown("**üè∑Ô∏è Tags:**")
                            tags_text = ", ".join(article_data['tags'])
                            st.markdown(f"*{tags_text}*")
                    
                    # Subt√≠tulo si existe
                    if article_data['subtitle']:
                        st.subheader("üìë Subt√≠tulo")
                        st.markdown(f"*{article_data['subtitle']}*")
                    
                    # Contenido del art√≠culo
                    if article_data['content']:
                        st.subheader("üìñ Contenido del Art√≠culo")
                        
                        # Opci√≥n para mostrar contenido completo o resumen
                        show_full_content = st.checkbox("Mostrar contenido completo", value=True)
                        
                        if show_full_content:
                            st.markdown(article_data['content'])
                        else:
                            # Mostrar solo los primeros 500 caracteres
                            preview = article_data['content'][:500] + "..." if len(article_data['content']) > 500 else article_data['content']
                            st.markdown(preview)
                            st.info("üí° Marca la casilla arriba para ver el contenido completo")
                    
                    # Informaci√≥n de debug si est√° habilitada
                    if show_debug:
                        st.subheader("üîß Informaci√≥n de Debug")
                        st.json(article_data)
                
                else:
                    st.session_state.stats['failed_extractions'] += 1
                    st.error("‚ö†Ô∏è No se pudo extraer contenido √∫til del art√≠culo. Verifica que la URL sea correcta y que contenga un art√≠culo.")
                
            except ValueError as e:
                st.session_state.stats['failed_extractions'] += 1
                st.markdown(f"""
                <div class="error-message">
                    ‚ùå <strong>Error de validaci√≥n:</strong><br>
                    {str(e)}
                </div>
                """, unsafe_allow_html=True)
                
            except Exception as e:
                st.session_state.stats['failed_extractions'] += 1
                st.error(f"‚ùå Error inesperado: {str(e)}")
                
                if show_debug:
                    st.exception(e)
    
    elif extract_button and not url_input.strip():
        st.warning("‚ö†Ô∏è Por favor, introduce una URL antes de extraer el contenido.")
    
    # Footer
    st.divider()
    
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col2:
        st.markdown("""
        <div style="text-align: center; color: #666; font-size: 0.9rem;">
            <p>üöÄ <strong>Ditto Scraper</strong> - POC desarrollado para extraer contenido de theobjetive.com</p>
            <p>Creado con ‚ù§Ô∏è usando Python, BeautifulSoup y Streamlit</p>
        </div>
        """, unsafe_allow_html=True)

if __name__ == "__main__":
    main() 